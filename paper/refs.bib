
@InProceedings{Chen2018,
  title = 	 {{P}ixel{SNAIL}: An Improved Autoregressive Generative Model},
  author =       {Chen, XI and Mishra, Nikhil and Rohaninejad, Mostafa and Abbeel, Pieter},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {864--872},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/chen18h/chen18h.pdf},
  url = 	 {https://proceedings.mlr.press/v80/chen18h.html},
  abstract = 	 {Autoregressive generative models achieve the best results in density estimation tasks involving high dimensional data, such as images or audio. They pose density estimation as a sequence modeling task, where a recurrent neural network (RNN) models the conditional distribution over the next element conditioned on all previous elements. In this paradigm, the bottleneck is the extent to which the RNN can model long-range dependencies, and the most successful approaches rely on causal convolutions. Taking inspiration from recent work in meta reinforcement learning, where dealing with long-range dependencies is also essential, we introduce a new generative model architecture that combines causal convolutions with self attention. In this paper, we describe the resulting model and present state-of-the-art log-likelihood results on heavily benchmarked datasets: CIFAR-10, $32 \times 32$ ImageNet and $64 \times 64$ ImageNet. Our implementation will be made available at \url{https://github.com/neocxi/pixelsnail-public}.}
}

@InProceedings{Germain2015,
  title = 	 {MADE: Masked Autoencoder for Distribution Estimation},
  author = 	 {Germain, Mathieu and Gregor, Karol and Murray, Iain and Larochelle, Hugo},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {881--889},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/germain15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/germain15.html},
  abstract = 	 {There has been a lot of recent interest in designing neural network models to estimate a distribution from a set of examples. We introduce a simple modification for autoencoder neural networks that yields powerful generative models. Our method masks the autoencoder’s parameters to respect autoregressive constraints: each input is reconstructed only from previous inputs in a given ordering. Constrained this way, the autoencoder outputs can be interpreted as a set of conditional probabilities, and their product, the full joint probability. We can also train a single network that can decompose the joint probability in multiple different orderings. Our simple framework can be applied to multiple architectures, including deep ones. Vectorized implementations, such as on GPUs, are simple and fast. Experiments demonstrate that this approach is competitive with state-of-the-art tractable distribution estimators. At test time, the method is significantly faster and scales better than other autoregressive estimators.}
}


@article{Crenshaw_2024,
doi = {10.3847/1538-3881/ad54bf},
url = {https://dx.doi.org/10.3847/1538-3881/ad54bf},
year = {2024},
month = {jul},
publisher = {The American Astronomical Society},
volume = {168},
number = {2},
pages = {80},
author = {John Franklin Crenshaw and J. Bryce Kalmbach and Alexander Gagliano and Ziang Yan and Andrew J. Connolly and Alex I. Malz and Samuel J. Schmidt and The LSST Dark Energy Science Collaboration},
title = {Probabilistic Forward Modeling of Galaxy Catalogs with Normalizing Flows},
journal = {The Astronomical Journal},
abstract = {Evaluating the accuracy and calibration of the redshift posteriors produced by photometric redshift (photo-z) estimators is vital for enabling precision cosmology and extragalactic astrophysics with modern wide-field photometric surveys. Evaluating photo-z posteriors on a per-galaxy basis is difficult, however, as real galaxies have a true redshift but not a true redshift posterior. We introduce PZFlow, a Python package for the probabilistic forward modeling of galaxy catalogs with normalizing flows. For catalogs simulated with PZFlow, there is a natural notion of “true” redshift posteriors that can be used for photo-z validation. We use PZFlow to simulate a photometric galaxy catalog where each galaxy has a redshift, noisy photometry, shape information, and a true redshift posterior. We also demonstrate the use of an ensemble of normalizing flows for photo-z estimation. We discuss how PZFlow will be used to validate the photo-z estimation pipeline of the Dark Energy Science Collaboration, and the wider applicability of PZFlow for statistical modeling of any tabular data.}
}



@inproceedings{Papamakarios2017a,
 author = {Papamakarios, George and Pavlakou, Theo and Murray, Iain},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Masked Autoregressive Flow for Density Estimation},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/6c1da886822c67822bcf3679d04369fa-Paper.pdf},
 volume = {30},
 year = {2017}
}


@inproceedings{Vaswani2017,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}


@inproceedings{huang2019solving,
title={Solving {ODE} with Universal Flows: Approximation Theory for Flow-Based Models},
author={Chin-Wei Huang and Laurent Dinh and Aaron Courville},
booktitle={ICLR 2020 Workshop on Integration of Deep Neural Models and Differential Equations},
year={2019},
url={https://openreview.net/forum?id=cfKpOiUzF}
}

@ARTICLE{Bogachev2005,
       author = {{Bogachev}, V.~I. and {Kolesnikov}, A.~V. and {Medvedev}, K.~V.},
        title = "{Triangular transformations of measures}",
      journal = {Sbornik: Mathematics},
         year = 2005,
        month = apr,
       volume = {196},
       number = {3},
        pages = {309-335},
          doi = {10.1070/SM2005v196n03ABEH000882},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2005SbMat.196..309B},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@article{Papamakarios2021,
  author  = {George Papamakarios and Eric Nalisnick and Danilo Jimenez Rezende and Shakir Mohamed and Balaji Lakshminarayanan},
  title   = {Normalizing Flows for Probabilistic Modeling and Inference},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {57},
  pages   = {1--64},
  url     = {http://jmlr.org/papers/v22/19-1028.html}
}

@article{weng2018flow,
  title   = "Flow-based Deep Generative Models",
  author  = "Weng, Lilian",
  journal = "lilianweng.github.io",
  year    = "2018",
  url     = "https://lilianweng.github.io/posts/2018-10-13-flow-models/"
}

@article{Tabak2010,
author = {Esteban G. Tabak and Eric Vanden-Eijnden},
title = {{Density estimation by dual ascent of the log-likelihood}},
volume = {8},
journal = {Communications in Mathematical Sciences},
number = {1},
publisher = {International Press of Boston},
pages = {217 -- 233},
keywords = {Density estimation, machine learning, maximum likelihood},
year = {2010},
}

@article{Tabak2013a,
author = {Tabak, E. G. and Turner, Cristina V.},
title = {A Family of Nonparametric Density Estimation Algorithms},
journal = {Communications on Pure and Applied Mathematics},
volume = {66},
number = {2},
pages = {145-164},
doi = {https://doi.org/10.1002/cpa.21423},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpa.21423},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpa.21423},
abstract = {Abstract A new methodology for density estimation is proposed. The methodology, which builds on the one developed by Tabak and Vanden-Eijnden, normalizes the data points through the composition of simple maps. The parameters of each map are determined through the maximization of a local quadratic approximation to the log-likelihood. Various candidates for the elementary maps of each step are proposed; criteria for choosing one includes robustness, computational simplicity, and good behavior in high-dimensional settings. A good choice is that of localized radial expansions, which depend on a single parameter: all the complexity of arbitrary, possibly convoluted probability densities can be built through the composition of such simple maps. © 2012 Wiley Periodicals, Inc.},
year = {2013}
}


@inproceedings{Rezende2015,
author = {Rezende, Danilo Jimenez and Mohamed, Shakir},
title = {Variational inference with normalizing flows},
year = {2015},
publisher = {JMLR.org},
abstract = {The choice of approximate posterior distribution is one of the core problems in variational inference. Most applications of variational inference employ simple families of posterior approximations in order to allow for efficient inference, focusing on mean-field or other simple structured approximations. This restriction has a significant impact on the quality of inferences made using variational methods. We introduce a new approach for specifying flexible, arbitrarily complex and scalable approximate posterior distributions. Our approximations are distributions constructed through a normalizing flow, whereby a simple initial density is transformed into a more complex one by applying a sequence of invertible transformations until a desired level of complexity is attained. We use this view of normalizing flows to develop categories of finite and infinitesimal flows and provide a unified view of approaches for constructing rich posterior approximations. We demonstrate that the theoretical advantages of having posteriors that better match the true posterior, combined with the scalability of amortized variational approaches, provides a clear improvement in performance and applicability of variational inference.},
booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
pages = {1530–1538},
numpages = {9},
location = {Lille, France},
series = {ICML'15}
}

@ARTICLE{2014arXiv1410.8516D,
       author = {{Dinh}, Laurent and {Krueger}, David and {Bengio}, Yoshua},
        title = "{NICE: Non-linear Independent Components Estimation}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning},
         year = 2014,
        month = oct,
          eid = {arXiv:1410.8516},
        pages = {arXiv:1410.8516},
archivePrefix = {arXiv},
       eprint = {1410.8516},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2014arXiv1410.8516D},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inproceedings{DinhKB14,
  author       = {Laurent Dinh and
                  David Krueger and
                  Yoshua Bengio},
  editor       = {Yoshua Bengio and
                  Yann LeCun},
  title        = {{NICE:} Non-linear Independent Components Estimation},
  booktitle    = {3rd International Conference on Learning Representations, {ICLR} 2015,
                  San Diego, CA, USA, May 7-9, 2015, Workshop Track Proceedings},
  year         = {2015},
  url          = {http://arxiv.org/abs/1410.8516},
  timestamp    = {Fri, 02 Aug 2024 11:44:53 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/DinhKB14.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{2016arXiv160508803D,
       author = {{Dinh}, Laurent and {Sohl-Dickstein}, Jascha and {Bengio}, Samy},
        title = "{Density estimation using Real NVP}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
         year = 2016,
        month = may,
          eid = {arXiv:1605.08803},
        pages = {arXiv:1605.08803},
archivePrefix = {arXiv},
       eprint = {1605.08803},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2016arXiv160508803D},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
@inproceedings{DinhSB17,
  author       = {Laurent Dinh and
                  Jascha Sohl{-}Dickstein and
                  Samy Bengio},
  title        = {Density estimation using Real {NVP}},
  booktitle    = {5th International Conference on Learning Representations, {ICLR} 2017,
                  Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  publisher    = {OpenReview.net},
  year         = {2017},
  url          = {https://openreview.net/forum?id=HkpbnH9lx},
  timestamp    = {Thu, 25 Jul 2019 14:25:58 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/DinhSB17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{brock2018large,
title={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},
author={Andrew Brock and Jeff Donahue and Karen Simonyan},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=B1xsqj09Fm},
}

@inproceedings{engel2018latent,
title={Latent Constraints: Learning to Generate Conditionally from Unconditional Generative Models},
author={Jesse Engel and Matthew Hoffman and Adam Roberts},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=Sy8XvGb0-},
}

@article{Takida2022,
author = {Takida, Yuhta and Liao, Wei-Hsiang and Lai, Chieh-Hsin and Uesaka, Toshimitsu and Takahashi, Shusuke and Mitsufuji, Yuki},
title = {Preventing oversmoothing in VAE via generalized variance parameterization},
year = {2022},
issue_date = {Oct 2022},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {509},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2022.08.067},
doi = {10.1016/j.neucom.2022.08.067},
journal = {Neurocomput.},
month = {oct},
pages = {137–156},
numpages = {20},
keywords = {Maximum likelihood estimation, Decoder variance, Posterior collapse, Variational autoencoders, Gaussian model, Bayesian inference}
}

@article{JMLR:v21:19-047,
  author  = {Mathieu Andreux and Tomás Angles and Georgios Exarchakis and Roberto Leonarduzzi and Gaspar Rochette and Louis Thiry and John Zarka and Stéphane Mallat and Joakim Andén and Eugene Belilovsky and Joan Bruna and Vincent Lostanlen and Muawiz Chaudhary and Matthew J. Hirn and Edouard Oyallon and Sixin Zhang and Carmine Cella and Michael Eickenberg},
  title   = {Kymatio: Scattering Transforms in Python},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {60},
  pages   = {1--6},
  url     = {http://jmlr.org/papers/v21/19-047.html}
}

@article{Unser2013,
author = {Unser, Michael and Chenouard, Nicolas},
title = {A Unifying Parametric Framework for 2D Steerable Wavelet Transforms},
journal = {SIAM Journal on Imaging Sciences},
volume = {6},
number = {1},
pages = {102-135},
year = {2013},
doi = {10.1137/120866014},
URL = {https://doi.org/10.1137/120866014},
eprint = {https://doi.org/10.1137/120866014},
abstract = { We introduce a complete parameterization of the family of two-dimensional steerable wavelets that are polar-separable in the Fourier domain under the constraint of self-reversibility. These wavelets are constructed by multiorder generalized Riesz transformation of a primary isotropic bandpass pyramid. The backbone of the transform (pyramid) is characterized by a radial frequency profile function \$h(\omega)\$, while the directional wavelet components at each scale are encoded by an \$M \times (2N+1)\$ shaping matrix \${\bf U}\$, where \$M\$ is the number of wavelet channels and \$N\$ the order of the Riesz transform. We provide general conditions on \$h(\omega)\$ and \${\bf U}\$ for the underlying wavelet system to form a tight frame of \$L\_2(\mathbb{R}^2)\$ (with a redundancy factor \$4/3M\$). The proposed framework ensures that the wavelets are steerable and provides new degrees of freedom (shaping matrix \${\bf U}\$) that can be exploited for designing specific wavelet systems. It encompasses many known transforms as particular cases: Simoncelli's steerable pyramid, Marr gradient and Hessian wavelets, monogenic wavelets, and \$N\$th-order Riesz and circular harmonic wavelets. We take advantage of the framework to construct new generalized spheroidal prolate wavelets, whose angular selectivity is maximized, as well as signal-adapted detectors based on principal component analysis. We also introduce a curvelet-like steerable wavelet system. Finally, we illustrate the advantages of some of the designs for signal denoising, feature extraction, pattern analysis, and source separation. }
}





@inproceedings{Mohan2020Robust,
title={Robust And Interpretable Blind Image Denoising Via Bias-Free Convolutional Neural Networks},
author={Sreyas Mohan and Zahra Kadkhodaie and Eero P. Simoncelli and Carlos Fernandez-Granda},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HJlSmC4FPS}
}

@Article{sdss,
  author	= {{York}, D.~G. and {Adelman}, J. and {Anderson}, J.~E., Jr.
		  and {Anderson}, S.~F. and {Annis}, J. and {Bahcall}, N.~A.
		  and {Bakken}, J.~A. and {Barkhouser}, R. and {Bastian}, S.
		  and {Berman}, E. and others},
  title		= "{The Sloan Digital Sky Survey: Technical Summary}",
  journal	= {\aj},
  keywords	= {Cosmology: Observations, Instrumentation: Miscellaneous,
		  Astrophysics},
  year		= 2000,
  month		= sep,
  volume	= {120},
  number	= {3},
  pages		= {1579-1587},
  doi		= {10.1086/301513},
  archiveprefix	= {arXiv},
  eprint	= {astro-ph/0006396},
  primaryclass	= {astro-ph},
  adsurl	= {https://ui.adsabs.harvard.edu/abs/2000AJ....120.1579Y},
  adsnote	= {Provided by the SAO/NASA Astrophysics Data System}
}

@Article{sdssdr7,
  doi		= {10.1088/0067-0049/182/2/543},
  url		= {https://doi.org/10.1088/0067-0049/182/2/543},
  year		= 2009,
  month		= {may},
  publisher	= {American Astronomical Society},
  volume	= {182},
  number	= {2},
  pages		= {543--558},
  author	= {Kevork N. Abazajian and Jennifer K. Adelman-McCarthy and
		  Marcel A. Agüeros and Sahar S. Allam and Carlos Allende
		  Prieto and Deokkeun An and Kurt S. J. Anderson and Scott F.
		  Anderson and James Annis and Neta A. Bahcall and C. A. L.
		  Bailer-Jones and J. C. Barentine and Bruce A. Bassett and
		  Andrew C. Becker and Timothy C. Beers and Eric F. Bell and
		  Vasily Belokurov and Andreas A. Berlind and Eileen F.
		  Berman and Mariangela Bernardi and Steven J. Bickerton and
		  Dmitry Bizyaev and John P. Blakeslee and Michael R. Blanton
		  and John J. Bochanski and William N. Boroski and Howard J.
		  Brewington and Jarle Brinchmann and J. Brinkmann and Robert
		  J. Brunner and Tam{\'{a}}s Budav{\'{a}}ri and Larry N.
		  Carey and Samuel Carliles and Michael A. Carr and Francisco
		  J. Castander and David Cinabro and A. J. Connolly and
		  Istv{\'{a}}n Csabai and Carlos E. Cunha and Paul C.
		  Czarapata and James R. A. Davenport and Ernst de Haas and
		  Ben Dilday and Mamoru Doi and Daniel J. Eisenstein and
		  Michael L. Evans and N. W. Evans and Xiaohui Fan and Scott
		  D. Friedman and Joshua A. Frieman and Masataka Fukugita and
		  Boris T. Gänsicke and Evalyn Gates and Bruce Gillespie and
		  G. Gilmore and Belinda Gonzalez and Carlos F. Gonzalez and
		  Eva K. Grebel and James E. Gunn and Zsuzsanna Györy and
		  Patrick B. Hall and Paul Harding and Frederick H. Harris
		  and Michael Harvanek and Suzanne L. Hawley and Jeffrey J.
		  E. Hayes and Timothy M. Heckman and John S. Hendry and
		  Gregory S. Hennessy and Robert B. Hindsley and J. Hoblitt
		  and Craig J. Hogan and David W. Hogg and Jon A. Holtzman
		  and Joseph B. Hyde and Shin-ichi Ichikawa and Takashi
		  Ichikawa and Myungshin Im and {\v{Z}}eljko Ivezi{\'{c}} and
		  Sebastian Jester and Linhua Jiang and Jennifer A. Johnson
		  and Anders M. Jorgensen and Mario Juri{\'{c}} and Stephen
		  M. Kent and R. Kessler and S. J. Kleinman and G. R. Knapp
		  and Kohki Konishi and Richard G. Kron and Jurek Krzesinski
		  and Nikolay Kuropatkin and Hubert Lampeitl and Svetlana
		  Lebedeva and Myung Gyoon Lee and Young Sun Lee and R.
		  French Leger and S{\'{e}}bastien L{\'{e}}pine and Nolan Li
		  and Marcos Lima and Huan Lin and Daniel C. Long and Craig
		  P. Loomis and Jon Loveday and Robert H. Lupton and Eugene
		  Magnier and Olena Malanushenko and Viktor Malanushenko and
		  Rachel Mandelbaum and Bruce Margon and John P. Marriner and
		  David Mart{\'{\i}}nez-Delgado and Takahiko Matsubara and
		  Peregrine M. McGehee and Timothy A. McKay and Avery Meiksin
		  and Heather L. Morrison and Fergal Mullally and Jeffrey A.
		  Munn and Tara Murphy and Thomas Nash and Ada Nebot and Eric
		  H. Neilsen and Heidi Jo Newberg and Peter R. Newman and
		  Robert C. Nichol and Tom Nicinski and Maria
		  Nieto-Santisteban and Atsuko Nitta and Sadanori Okamura and
		  Daniel J. Oravetz and Jeremiah P. Ostriker and Russell Owen
		  and Nikhil Padmanabhan and Kaike Pan and Changbom Park and
		  George Pauls and John Peoples and Will J. Percival and
		  Jeffrey R. Pier and Adrian C. Pope and Dimitri Pourbaix and
		  Paul A. Price and Norbert Purger and Thomas Quinn and M.
		  Jordan Raddick and Paola Re Fiorentin and Gordon T.
		  Richards and Michael W. Richmond and Adam G. Riess and
		  Hans-Walter Rix and Constance M. Rockosi and Masao Sako and
		  David J. Schlegel and Donald P. Schneider and Ralf-Dieter
		  Scholz and Matthias R. Schreiber and Axel D. Schwope and
		  Uro{\v{s}} Seljak and Branimir Sesar and Erin Sheldon and
		  Kazu Shimasaku and Valena C. Sibley and A. E. Simmons and
		  Thirupathi Sivarani and J. Allyn Smith and Martin C. Smith
		  and Vernesa Smol{\v{c}}i{\'{c}} and Stephanie A. Snedden
		  and Albert Stebbins and Matthias Steinmetz and Chris
		  Stoughton and Michael A. Strauss and Mark SubbaRao and
		  Yasushi Suto and Alexander S. Szalay and Istv{\'{a}}n
		  Szapudi and Paula Szkody and Masayuki Tanaka and Max
		  Tegmark and Luis F. A. Teodoro and Aniruddha R. Thakar and
		  Christy A. Tremonti and Douglas L. Tucker and Alan Uomoto
		  and Daniel E. Vanden Berk and Jan Vandenberg and S. Vidrih
		  and Michael S. Vogeley and Wolfgang Voges and Nicole P.
		  Vogt and Yogesh Wadadekar and Shannon Watters and David H.
		  Weinberg and Andrew A. West and Simon D. M. White and Brian
		  C. Wilhite and Alainna C. Wonders and Brian Yanny and D. R.
		  Yocum and Donald G. York and Idit Zehavi and Stefano
		  Zibetti and Daniel B. Zucker},
  title		= {THE SEVENTH DATA RELEASE OF THE SLOAN DIGITAL SKY SURVEY},
  journal	= {The Astrophysical Journal Supplement Series}
}

@misc{mandelbaum_2019_3242143,
  author       = {Mandelbaum, Rachel and
                  Lackner, Claire and
                  Leauthaud, Alexie and
                  Rowe, Barnaby},
  title        = {COSMOS real galaxy dataset},
  month        = jul,
  year         = 2019,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.3242143},
  url          = {https://doi.org/10.5281/zenodo.3242143}
}

@INPROCEEDINGS{Hataya2023,
author = {R. Hataya and H. Bao and H. Arai},
booktitle = {2023 IEEE/CVF International Conference on Computer Vision (ICCV)},
title = {Will Large-scale Generative Models Corrupt Future Datasets?},
year = {2023},
volume = {},
issn = {},
pages = {20498-20508},
abstract = {Recently proposed large-scale text-to-image generative models such as DALL•E 2 [47], Midjourney [42], and StableDiffusion [51] can generate high-quality and realistic images from users’ prompts. Not limited to the research community, ordinary Internet users enjoy these generative models, and consequently, a tremendous amount of generated images have been shared on the Internet. Meanwhile, today’s success of deep learning in the computer vision field owes a lot to images collected from the Internet. These trends lead us to a research question: &quot;will such generated images impact the quality of future datasets and the performance of computer vision models positively or negatively?&quot; This paper empirically answers this question by simulating contamination. Namely, we generate ImageNet-scale and COCO-scale datasets using a state-of-the-art generative model and evaluate models trained with &quot;contaminated&quot; datasets on various tasks, including image classification and image generation. Throughout experiments, we conclude that generated images negatively affect downstream performance, while the significance depends on tasks and the amount of generated images. The generated datasets and the codes for experiments will be publicly released for future research. Generated datasets and source codes are available from https://github.com/moskomule/dataset-contamination.},
keywords = {computer vision;image synthesis;computational modeling;watermarking;market research;information filters;data models},
doi = {10.1109/ICCV51070.2023.01879},
url = {https://doi.ieeecomputersociety.org/10.1109/ICCV51070.2023.01879},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {oct}
}



@conference{ravanbakhsh2016,
author = {S. Ravanbakhsh and F. Lanusse and R. Mandelbaum and J. Schneider and B. Poczos},
title = {Enabling Dark Energy Science with Deep Generative Models of Galaxy Images},
booktitle = {Proceedings of 31st AAAI Conference on Artificial Intelligence (AAAI '17)},
year = {2017},
month = {February},
pages = {1488 - 1494},
eid		= {arXiv:1609.05796},
archiveprefix	= {arXiv},
eprint	= {1609.05796},
}




@article{smith2021,
    author = {Smith, Michael J and Geach, James E and Jackson, Ryan A and Arora, Nikhil and Stone, Connor and Courteau, Stéphane},
    title = "{Realistic galaxy image simulation via score-based generative models}",
    journal = {Monthly Notices of the Royal Astronomical Society},
    volume = {511},
    number = {2},
    pages = {1808-1818},
    year = {2022},
    month = {01},
    abstract = "{We show that a denoising diffusion probabilistic model (DDPM), a class of score-based generative model, can be used to produce realistic mock images that mimic observations of galaxies. Our method is tested with Dark Energy Spectroscopic Instrument (DESI) grz imaging of galaxies from the Photometry and Rotation curve OBservations from Extragalactic Surveys (PROBES) sample and galaxies selected from the Sloan Digital Sky Survey. Subjectively, the generated galaxies are highly realistic when compared with samples from the real data set. We quantify the similarity by borrowing from the deep generative learning literature, using the ‘Fréchet inception distance’ to test for subjective and morphological similarity. We also introduce the ‘synthetic galaxy distance’ metric to compare the emergent physical properties (such as total magnitude, colour, and half-light radius) of a ground truth parent and synthesized child data set. We argue that the DDPM approach produces sharper and more realistic images than other generative methods such as adversarial networks (with the downside of more costly inference), and could be used to produce large samples of synthetic observations tailored to a specific imaging survey. We demonstrate two potential uses of the DDPM: (1) accurate inpainting of occluded data, such as satellite trails, and (2) domain transfer, where new input images can be processed to mimic the properties of the DDPM training set. Here we ‘DESI-fy’ cartoon images as a proof of concept for domain transfer. Finally, we suggest potential applications for score-based approaches that could motivate further research on this topic within the astronomical community.}",
    issn = {0035-8711},
    doi = {10.1093/mnras/stac130},
    url = {https://doi.org/10.1093/mnras/stac130},
    eprint = {https://academic.oup.com/mnras/article-pdf/511/2/1808/47158945/stac130.pdf},
}





@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}


@inproceedings{Kingma2014,
  abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
  added-at = {2020-10-15T14:36:56.000+0200},
  author = {Kingma, Diederik P. and Welling, Max},
  biburl = {https://www.bibsonomy.org/bibtex/242e5be6faa01cba2587f4907ac99dce8/annakrause},
  booktitle = {2nd International Conference on Learning Representations, {ICLR} 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
  eprint = {http://arxiv.org/abs/1312.6114},
  eprintclass = {stat.ML},
  eprinttype = {arXiv},
  interhash = {a626a9d77a123c52405a08da983203cb},
  intrahash = {42e5be6faa01cba2587f4907ac99dce8},
  keywords = {cs.LG stat.ML vae},
  timestamp = {2021-02-01T17:13:18.000+0100},
  title = {{Auto-Encoding Variational Bayes}},
  year = 2014
}


@inproceedings{janulewicz2024assessing,
title={Assessing the Viability of Generative Modeling in Simulated Astronomical Observations},
author={Patrick Janulewicz and Laurence Perreault-Levasseur and Tracy Webb},
booktitle={ICML 2024 Workshop on Structured Probabilistic Inference {\&} Generative Modeling},
year={2024},
url={https://openreview.net/forum?id=lzLMJ6KkiS}
}

@article{HACKSTEIN2023100685,
title = {Evaluation metrics for galaxy image generators},
journal = {Astronomy and Computing},
volume = {42},
pages = {100685},
year = {2023},
issn = {2213-1337},
doi = {https://doi.org/10.1016/j.ascom.2022.100685},
url = {https://www.sciencedirect.com/science/article/pii/S2213133722000993},
author = {S. Hackstein and V. Kinakh and C. Bailer and M. Melchior},
keywords = {Deep learning, Generative models, Computer-vision, Evaluation, Galaxy morphology},
abstract = {A major problem with deep generative models is verifying that the generated distribution resembles the target distribution while the individual generated sample is indistinguishable from the original data. In particular, for application in astrophysics we need to be sure that the generated data matches our prior knowledge and that the generated samples entail all object types with the correct frequency and diversity. We currently lack objective ways to systematically assess these quality aspects, where human inspection reaches its limits, as this requires detailed analysis of a large data volume. In this work, we identify reasonable metrics for the quality of galaxy image generators. To this end, we compare a small set of conditional image generators, trained on galaxy images with classification labels for visual morphology features. Our main contribution is a new set of cluster-based metrics for matching the generated distribution to the target distribution. Furthermore, we use the Wasserstein distance on proxies for galaxy morphology as well as a number of other metrics commonly used for image generators. The newly introduced cluster-based metrics are good proxies for the quality of the generated distribution and are suited for automatized identification of mode collapse. Furthermore, the cluster metrics allow for a qualitative interpretation of the generated distribution. The metrics based on morphological statistics provide a useful tool to probe the physical soundness of generated samples. Finally, we find that kernel inception distance used with an InceptionV3 model pre-trained on ImageNet is a good proxy for the overall quality of galaxy image generators, although it cannot be interpreted that easily.}
}

@article{PhysRevD.107.076017,
  title = {Evaluating generative models in high energy physics},
  author = {Kansal, Raghav and Li, Anni and Duarte, Javier and Chernyavskaya, Nadezda and Pierini, Maurizio and Orzari, Breno and Tomei, Thiago},
  journal = {Phys. Rev. D},
  volume = {107},
  issue = {7},
  pages = {076017},
  numpages = {18},
  year = {2023},
  month = {Apr},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevD.107.076017},
  url = {https://link.aps.org/doi/10.1103/PhysRevD.107.076017}
}


@article{Arcelin2020,
    author = {Arcelin, Bastien and Doux, Cyrille and Aubourg, Eric and Roucelle, Cécile and (The LSST Dark Energy Science Collaboration)},
    title = "{Deblending galaxies with variational autoencoders: A joint multiband, multi-instrument approach}",
    journal = {Monthly Notices of the Royal Astronomical Society},
    volume = {500},
    number = {1},
    pages = {531-547},
    year = {2020},
    month = {10},
    abstract = "{Blending of galaxies has a major contribution in the systematic error budget of weak-lensing studies, affecting photometric and shape measurements, particularly for ground-based, deep, photometric galaxy surveys, such as the Rubin Observatory Legacy Survey of Space and Time (LSST). Existing deblenders mostly rely on analytic modelling of galaxy profiles and suffer from the lack of flexible yet accurate models. We propose to use generative models based on deep neural networks, namely variational autoencoders (VAE), to learn probabilistic models directly from data. We train a VAE on images of centred, isolated galaxies, which we reuse, as a prior, in a second VAE-like neural network in charge of deblending galaxies. We train our networks on simulated images including six LSST bandpass filters and the visible and near-infrared bands of the Euclid satellite, as our method naturally generalizes to multiple bands and can incorporate data from multiple instruments. We obtain median reconstruction errors on ellipticities and r-band magnitude between ±0.01 and ±0.05, respectively, in most cases, and ellipticity multiplicative bias of 1.6 per cent for blended objects in the optimal configuration. We also study the impact of decentring and prove the method to be robust. This method only requires the approximate centre of each target galaxy, but no assumptions about the number of surrounding objects, pointing to an iterative detection/deblending procedure we leave for future work. Finally, we discuss future challenges about training on real data and obtain encouraging results when applying transfer learning.}",
    issn = {0035-8711},
    doi = {10.1093/mnras/staa3062},
    url = {https://doi.org/10.1093/mnras/staa3062},
    eprint = {https://academic.oup.com/mnras/article-pdf/500/1/531/34292544/staa3062.pdf},
}



@article{ROWE2015121,
title = {GalSim: The modular galaxy image simulation toolkit},
journal = {Astronomy and Computing},
volume = {10},
pages = {121-150},
year = {2015},
issn = {2213-1337},
doi = {https://doi.org/10.1016/j.ascom.2015.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S221313371500013X},
author = {B.T.P. Rowe and M. Jarvis and R. Mandelbaum and G.M. Bernstein and J. Bosch and M. Simet and J.E. Meyers and T. Kacprzak and R. Nakajima and J. Zuntz and H. Miyatake and J.P. Dietrich and R. Armstrong and P. Melchior and M.S.S. Gill},
keywords = {Methods: data analysis, Techniques: image processing, Gravitational lensing, Cosmology: observations},
abstract = {GalSim is a collaborative, open-source project aimed at providing an image simulation tool of enduring benefit to the astronomical community. It provides a software library for generating images of astronomical objects such as stars and galaxies in a variety of ways, efficiently handling image transformations and operations such as convolution and rendering at high precision. We describe the GalSim software and its capabilities, including necessary theoretical background. We demonstrate that the performance of GalSim meets the stringent requirements of high precision image analysis applications such as weak gravitational lensing, for current datasets and for the Stage IV dark energy surveys of the Large Synoptic Survey Telescope, ESA’s Euclid mission, and NASA’s WFIRST-AFTA mission. The GalSim project repository is public and includes the full code history, all open and closed issues, installation instructions, documentation, and wiki pages (including a Frequently Asked Questions section). The GalSim repository can be found at https://github.com/GalSim-developers/GalSim.}
}

@article{Lanusse2021,
    author = {Lanusse, François and Mandelbaum, Rachel and Ravanbakhsh, Siamak and Li, Chun-Liang and Freeman, Peter and Póczos, Barnabás},
    title = "{Deep generative models for galaxy image simulations}",
    journal = {Monthly Notices of the Royal Astronomical Society},
    volume = {504},
    number = {4},
    pages = {5543-5555},
    year = {2021},
    month = {05},
    abstract = "{Image simulations are essential tools for preparing and validating the analysis of current and future wide-field optical surveys. However, the galaxy models used as the basis for these simulations are typically limited to simple parametric light profiles, or use a fairly limited amount of available space-based data. In this work, we propose a methodology based on deep generative models to create complex models of galaxy morphologies that may meet the image simulation needs of upcoming surveys. We address the technical challenges associated with learning this morphology model from noisy and point spread function (PSF)-convolved images by building a hybrid Deep Learning/physical Bayesian hierarchical model for observed images, explicitly accounting for the PSF and noise properties. The generative model is further made conditional on physical galaxy parameters, to allow for sampling new light profiles from specific galaxy populations. We demonstrate our ability to train and sample from such a model on galaxy postage stamps from the HST/ACS COSMOS survey, and validate the quality of the model using a range of second- and higher order morphology statistics. Using this set of statistics, we demonstrate significantly more realistic morphologies using these deep generative models compared to conventional parametric models. To help make these generative models practical tools for the community, we introduce galsim-hub, a community-driven repository of generative models, and a framework for incorporating generative models within the galsim image simulation software.}",
    issn = {0035-8711},
    doi = {10.1093/mnras/stab1214},
    url = {https://doi.org/10.1093/mnras/stab1214},
    eprint = {https://academic.oup.com/mnras/article-pdf/504/4/5543/38036124/stab1214.pdf},
}

@INPROCEEDINGS{Zhang2017,
  author={Zhang, Han and Xu, Tao and Li, Hongsheng and Zhang, Shaoting and Wang, Xiaogang and Huang, Xiaolei and Metaxas, Dimitris},
  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)}, 
  title={StackGAN: Text to Photo-Realistic Image Synthesis with Stacked Generative Adversarial Networks}, 
  year={2017},
  volume={},
  number={},
  pages={5908-5916},
  keywords={Gallium nitride;Training;Generators;Manifolds;Image resolution;Shape;Gaussian distribution},
  doi={10.1109/ICCV.2017.629}
}

@article{Fussell2019,
    author = {Fussell, Levi and Moews, Ben},
    title = "{Forging new worlds: high-resolution synthetic galaxies with chained generative adversarial networks}",
    journal = {Monthly Notices of the Royal Astronomical Society},
    volume = {485},
    number = {3},
    pages = {3203-3214},
    year = {2019},
    month = {03},
    abstract = "{Astronomy of the 21st century increasingly finds itself with extreme quantities of data. This growth in data is ripe for modern technologies such as deep image processing, which has the potential to allow astronomers to automatically identify, classify, segment, and deblend various astronomical objects. In this paper, we explore the use of chained generative adversarial networks (GANs), a class of generative models that learn mappings from latent spaces to data distributions by modelling the joint distribution of the data, to produce physically realistic galaxy images as one use case of such models. In cosmology, such data sets can aid in the calibration of shape measurements for weak lensing by augmenting data with synthetic images. By measuring the distributions of multiple physical properties, we show that images generated with our approach closely follow the distributions of real galaxies, further establishing state-of-the-art GAN architectures as a valuable tool for modern-day astronomy.}",
    issn = {0035-8711},
    doi = {10.1093/mnras/stz602},
    url = {https://doi.org/10.1093/mnras/stz602},
    eprint = {https://academic.oup.com/mnras/article-pdf/485/3/3203/28221657/stz602.pdf},
}




@article{Hemmati_2022,
doi = {10.3847/1538-4357/aca1b8},
url = {https://dx.doi.org/10.3847/1538-4357/aca1b8},
year = {2022},
month = {dec},
publisher = {The American Astronomical Society},
volume = {941},
number = {2},
pages = {141},
author = {Shoubaneh Hemmati and Eric Huff and Hooshang Nayyeri and Agnès Ferté and Peter Melchior and Bahram Mobasher and Jason Rhodes and Abtin Shahidi and Harry Teplitz},
title = {Deblending Galaxies with Generative Adversarial Networks},
journal = {The Astrophysical Journal},
abstract = {Deep generative models including generative adversarial networks (GANs) are powerful unsupervised tools in learning the distributions of data sets. Building a simple GAN architecture in PyTorch and training on the CANDELS data set, we generate galaxy images with the Hubble Space Telescope (HST) resolution starting from a noise vector. We proceed by modifying the GAN architecture to improve Subaru Hyper Suprime-Cam (HSC) ground-based images by increasing their resolution to the HST resolution. We use the super-resolution GAN on a large sample of blended galaxies, which we create using CANDELS cutouts. In our simulated blend sample, ∼20% would unrecognizably be blended even in the HST-resolution cutouts. In the HSC-like cutouts this fraction rises to ∼90%. With our modified GAN we can lower this value to ∼50%. We quantify the blending fraction in the high, low, and GAN resolutions over the whole manifold of angular separation, flux ratios, sizes, and redshift difference between the two blended objects. The two peaks found by the GAN deblender result in improvement by a factor of 10 in the photometry measurement of the blended objects. Modifying the architecture of the GAN, we also train a multiwavelength GAN with HST cutouts in seven optical + near-infrared bands. This multiwavelength GAN improves the fraction of detected blends by another ∼10% compared to the single-band GAN. This is most beneficial to the current and future precision cosmology experiments (e.g., LSST, SPHEREx, Euclid, Roman), specifically those relying on weak gravitational lensing, where blending is a major source of systematic error.}
}


@ARTICLE{Yu2015,
       author = {{Yu}, Fisher and {Seff}, Ari and {Zhang}, Yinda and {Song}, Shuran and {Funkhouser}, Thomas and {Xiao}, Jianxiong},
        title = "{LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition},
         year = 2015,
        month = jun,
          eid = {arXiv:1506.03365},
        pages = {arXiv:1506.03365},
          doi = {10.48550/arXiv.1506.03365},
archivePrefix = {arXiv},
       eprint = {1506.03365},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2015arXiv150603365Y},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



@INPROCEEDINGS{Liu2015,
  author={Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Deep Learning Face Attributes in the Wild}, 
  year={2015},
  volume={},
  number={},
  pages={3730-3738},
  keywords={Face;Feature extraction;Training;Face recognition;Machine learning;Support vector machines;Image recognition},
  doi={10.1109/ICCV.2015.425}
}


@inproceedings{KarrasALL18,
  title = {Progressive Growing of GANs for Improved Quality, Stability, and Variation},
  author = {Tero Karras and Timo Aila and Samuli Laine and Jaakko Lehtinen},
  year = {2018},
  url = {https://openreview.net/forum?id=Hk99zCeAb},
  researchr = {https://researchr.org/publication/KarrasALL18},
  cites = {0},
  citedby = {0},
  booktitle = {6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  publisher = {OpenReview.net},
}

@inproceedings{Kingma2018,
 author = {Kingma, Durk P and Dhariwal, Prafulla},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Glow: Generative Flow with Invertible 1x1 Convolutions},
 url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/d139db6a236200b21cc7f752979132d0-Paper.pdf},
 volume = {31},
 year = {2018}
}


@INPROCEEDINGS{Rombach2022,
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Björn},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
  year={2022},
  volume={},
  number={},
  pages={10674-10685},
  keywords={Training;Visualization;Image synthesis;Computational modeling;Noise reduction;Superresolution;Process control;Image and video synthesis and generation},
  doi={10.1109/CVPR52688.2022.01042}
}



@ARTICLE{ramesh2022,
       author = {{Ramesh}, Aditya and {Dhariwal}, Prafulla and {Nichol}, Alex and {Chu}, Casey and {Chen}, Mark},
        title = "{Hierarchical Text-Conditional Image Generation with CLIP Latents}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition},
         year = 2022,
        month = apr,
          eid = {arXiv:2204.06125},
        pages = {arXiv:2204.06125},
          doi = {10.48550/arXiv.2204.06125},
archivePrefix = {arXiv},
       eprint = {2204.06125},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220406125R},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



@inproceedings{Oppenlaender2022,
author = {Oppenlaender, Jonas},
title = {The Creativity of Text-to-Image Generation},
year = {2022},
isbn = {9781450399555},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3569219.3569352},
doi = {10.1145/3569219.3569352},
booktitle = {Proceedings of the 25th International Academic Mindtrek Conference},
pages = {192–202},
numpages = {11},
keywords = {text-to-image generation, text-guided image synthesis, prompt engineering, generative art, creativity, Midjourney, AI art},
location = {Tampere, Finland},
series = {Academic Mindtrek '22}
}

@inproceedings{kadkhodaie2024generalization,
title={Generalization in diffusion models arises from geometry-adaptive harmonic representations},
author={Zahra Kadkhodaie and Florentin Guth and Eero P Simoncelli and St{\'e}phane Mallat},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=ANvmVS2Yr0}
}

@article{Cheng:2023imk,
    author = {Cheng, Sihao and Morel, Rudy and Allys, Erwan and Ménard, Brice and Mallat, Stéphane},
    title = "{Scattering spectra models for physics}",
    journal = {PNAS Nexus},
    volume = {3},
    number = {4},
    pages = {pgae103},
    year = {2024},
    month = {03},
    abstract = "{Physicists routinely need probabilistic models for a number of tasks such as parameter inference or the generation of new realizations of a field. Establishing such models for highly non-Gaussian fields is a challenge, especially when the number of samples is limited. In this paper, we introduce scattering spectra models for stationary fields and we show that they provide accurate and robust statistical descriptions of a wide range of fields encountered in physics. These models are based on covariances of scattering coefficients, i.e. wavelet decomposition of a field coupled with a pointwise modulus. After introducing useful dimension reductions taking advantage of the regularity of a field under rotation and scaling, we validate these models on various multiscale physical fields and demonstrate that they reproduce standard statistics, including spatial moments up to fourth order. The scattering spectra provide us with a low-dimensional structured representation that captures key properties encountered in a wide range of physical fields. These generic models can be used for data exploration, classification, parameter inference, symmetry detection, and component separation.}",
    issn = {2752-6542},
    doi = {10.1093/pnasnexus/pgae103},
}


@article{Lee2019, 
doi = {10.21105/joss.01237}, 
year = {2019}, 
publisher = {The Open Journal}, 
volume = {4}, 
number = {36}, 
pages = {1237}, 
author = {Gregory R. Lee and Ralf Gommers and Filip Waselewski and Kai Wohlfahrt and Aaron O'Leary}, 
title = {PyWavelets: A Python package for wavelet analysis}, 
journal = {Journal of Open Source Software} 
}
 
@article{JMLR:v6:hyvarinen05a,
  author  = {Aapo Hyv{{\"a}}rinen},
  title   = {Estimation of Non-Normalized Statistical Models by Score Matching},
  journal = {Journal of Machine Learning Research},
  year    = {2005},
  volume  = {6},
  number  = {24},
  pages   = {695--709},
}
@InProceedings{DenoisingReview2023,
author="Rama Lakshmi, Gali
and Divya, G.
and Bhavya, D.
and Sai Jahnavi, Ch.
and Akila, B.",
editor="Bindhu, V.
and Tavares, Jo{\~a}o Manuel R. S.
and Vuppalapati, Chandrasekar",
title="A Review on Image Denoising Algorithms for Various Applications",
booktitle="Proceedings of Fourth International Conference on Communication, Computing and Electronics Systems ",
year="2023",
publisher="Springer Nature Singapore",
address="Singapore",
pages="839--847",
abstract="Image is well-known word in various fields like medical, engineering, and arts. A literature review is conducted on image qualities, and the need to improve the quality of image for various applications are identified. Numerous noises are added to an image both internally and externally in different stages which results in the poor quality of image. At few points, the noise in the image leads to loss of critical information and creates a lot of damage in that area. Purpose of this review is to gain knowledge about the image denoising and give details about denoising filter algorithms used for noise removal from images. Various techniques exist to overcome noise in any image. Multiple filters and combinations of filters have been designed to remove noise, and those are summarised in this paper for better understanding.",
isbn="978-981-19-7753-4"
}


@article{Wang2020,
author = {Wang, Hua and Fan, Linwei and Guo, Qiang and Zhang, Caiming},
year = {2020},
month = {01},
pages = {461-480},
title = {A review of image denoising methods},
volume = {20},
journal = {Communications in Information and Systems},
doi = {10.4310/CIS.2020.v20.n4.a4}
}

@misc{Mathematica,
  author = {{Wolfram Research, Inc.}},
  title = {Mathematica 13.1},
  url = {https://www.wolfram.com},
  year = {2022},
}
@misc{MATLAB,
author = {The MathWorks, Inc.},
year = {2024},
title = {MATLAB version: 24.1.0.2537033 (R2024a)},
publisher = {The MathWorks Inc.},
address = {Natick, Massachusetts, United States},
url = {https://www.mathworks.com}
}

@inproceedings{AlexNet2012,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 volume = {25},
 year = {2012}
}


@inproceedings{tweedie1947functions,
  title={Functions of a statistical variate with given means, with special reference to Laplacian distributions},
  author={Tweedie, MCK},
  booktitle={Mathematical Proceedings of the Cambridge Philosophical Society},
  volume={43},
  number={1},
  pages={41--49},
  year={1947},
  organization={Cambridge University Press}
}

@article{Jaynes1957,
  title = {Information Theory and Statistical Mechanics},
  author = {Jaynes, E. T.},
  journal = {Phys. Rev.},
  volume = {106},
  issue = {4},
  pages = {620--630},
  numpages = {0},
  year = {1957},
  month = {May},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRev.106.620},
}

@article{shannon1948mathematical,
  added-at = {2013-02-27T08:21:47.000+0100},
  author = {Shannon, Claude E.},
  biburl = {https://www.bibsonomy.org/bibtex/2b6bc42c140f0147cd6a1781d75fcb897/jaeschke},
  interhash = {754130207906fcec16a53d330eeff348},
  intrahash = {b6bc42c140f0147cd6a1781d75fcb897},
  journal = {The Bell System Technical Journal},
  keywords = {communication ddm entropy information mk3.3 shannon toread},
  month = {July, October},
  pages = {379--423, 623--656},
  timestamp = {2021-10-15T09:15:42.000+0200},
  title = {A Mathematical Theory of Communication},
  volume = 27,
  year = 1948
}


@inproceedings{Guth2022b,
 author = {Guth, Florentin and Coste, Simon and De Bortoli, Valentin and Mallat, Stephane},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {478--491},
 publisher = {Curran Associates, Inc.},
 title = {Wavelet Score-Based Generative Modeling},
 volume = {35},
 year = {2022},
 archivePrefix = {arXiv},
 eprint = {2208.05003},
}

@ARTICLE{chang2023design,
      title={On the Design Fundamentals of Diffusion Models: A Survey}, 
      author={Ziyi Chang and George Alex Koulieris and Hubert P. H. Shum},
      year={2023},
      eprint={2306.04542},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@ARTICLE{Guth2022a,
       author = {{Guth}, Florentin and {Coste}, Simon and {De Bortoli}, Valentin and {Mallat}, Stephane},
        title = "{Wavelet Score-Based Generative Modeling}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
         year = 2022,
        month = aug,
          eid = {arXiv:2208.05003},
        pages = {arXiv:2208.05003},
          doi = {10.48550/arXiv.2208.05003},
archivePrefix = {arXiv},
       eprint = {2208.05003},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220805003G},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



@article{Uhlenbeck1930,
  title = {On the Theory of the Brownian Motion},
  author = {Uhlenbeck, G. E. and Ornstein, L. S.},
  journal = {Phys. Rev.},
  volume = {36},
  issue = {5},
  pages = {823--841},
  numpages = {0},
  year = {1930},
  month = {Sep},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRev.36.823},
}

@article{robbins1964empirical,
  title={An empirical Bayes approach to statistics},
  author={Robbins, Herbert Ellis},
  journal={Matematika},
  volume={8},
  number={2},
  pages={133--140},
  year={1964}
}

@inproceedings{herbert1956empirical,
  title={An empirical Bayes approach to statistics},
  author={Herbert, Robbins},
  booktitle={Proceedings of the third berkeley symposium on mathematical statistics and probability},
  volume={1},
  pages={157--163},
  year={1956}
}

@article{miyasawa1961empirical,
  title={An empirical Bayes estimator of the mean of a normal population},
  author={Miyasawa, Koichi and others},
  journal={Bull. Inst. Internat. Statist},
  volume={38},
  number={181-188},
  pages={1--2},
  year={1961}
}

@article{Raphan2011,
author = {Raphan, Martin and Simoncelli, Eero P.},
title = {Least squares estimation without priors or supervision},
year = {2011},
issue_date = {February 2011},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {23},
number = {2},
issn = {0899-7667},
doi = {10.1162/NECO_a_00076},
abstract = {Selection of an optimal estimator typically relies on either supervised training samples (pairs of measurements and their associated true values) or a prior probability model for the true values. Here, we consider the problem of obtaining a least squares estimator given a measurement process with known statistics (i.e., a likelihood function) and a set of unsupervised measurements, each arising from a corresponding true value drawn randomly from an unknown distribution. We develop a general expression for a nonparametric empirical Bayes least squares (NEBLS) estimator, which expresses the optimal least squares estimator in terms of the measurement density, with no explicit reference to the unknown (prior) density. We study the conditions under which such estimators exist and derive specific forms for a variety of different measurement processes. We further show that each of these NEBLS estimators may be used to express the mean squared estimation error as an expectation over the measurement density alone, thus generalizing Stein's unbiased risk estimator (SURE), which provides such an expression for the additive gaussian noise case. This error expression may then be optimized over noisy measurement samples, in the absence of supervised training data, yielding a generalized SURE-optimized parametric least squares (SURE2PLS) estimator. In the special case of a linear parameterization (i.e., a sum of nonlinear kernel functions), the objective function is quadratic, and we derive an incremental form for learning this estimator from data. We also show that combining the NEBLS form with its corresponding generalized SURE expression produces a generalization of the score-matching procedure for parametric density estimation. Finally, we have implemented several examples of such estimators, and we show that their performance is comparable to their optimal Bayesian or supervised regression counterparts for moderate to large amounts of data.},
journal = {Neural Comput.},
month = {feb},
pages = {374–420},
numpages = {47}
}
@book{Wiener1949,
    author = {Wiener, Norbert},
    title = "{Extrapolation, Interpolation, and Smoothing of Stationary Time Series: With Engineering Applications}",
    publisher = {The MIT Press},
    year = {1949},
    month = {08},
    abstract = "{A book thatbecame the basis for modern communication theory, by a scientist considered one of the founders of the field of artifical intelligence.Some predict that Norbert Wiener will be remembered for his Extrapolation long after Cybernetics is forgotten. Indeed, few computer science students would know today what cybernetics is all about, while every communication student knows what Wiener's filter is. The original work was circulated as a classified memorandum in 1942, because it was connected with sensitive wartime efforts to improve radar communication. This book became the basis for modern communication theory, by a scientist considered one of the founders of the field of artifical intelligence. Combining ideas from statistics and time-series analysis, Wiener used Gauss's method of shaping the characteristic of a detector to allow for the maximal recognition of signals in the presence of noise. This method came to be known as the "Wiener filter."}",
    isbn = {9780262257190},
    doi = {10.7551/mitpress/2946.001.0001},
}




@article{MallatPeyre2008,
  TITLE = {{Orthogonal Bandlet Bases for Geometric Images Approximation}},
  AUTHOR = {Mallat, St{\'e}phane and Peyr{\'e}, Gabriel},
  URL = {https://hal.science/hal-00359740},
  JOURNAL = {{Communications on Pure and Applied Mathematics}},
  PUBLISHER = {{Wiley}},
  VOLUME = {61},
  NUMBER = {9},
  PAGES = {1173-1212},
  YEAR = {2008},
  MONTH = Sep,
  KEYWORDS = {Bandlets ; image compression ; orthogonal bandlets ; geometric images},
  HAL_ID = {hal-00359740},
  HAL_VERSION = {v1},
}

@book{korostelev1993minimax,
  title={Minimax Theory of Image Reconstruction},
  author={Korostelev, A.P. and Tsybakov, A.B.},
  isbn={9783540940289},
  lccn={93018028},
  series={Lecture notes in statistics},
  year={1993},
  publisher={Springer-Verlag}
}

@article{Ferroukhi2019,
author = {Ferroukhi, Merzak and Ouahabi, A. and Attari, Mokhtar and taleb-ahmed, Abdelmalik},
year = {2019},
month = {01},
pages = {88},
title = {Medical Video Coding Based on 2nd-Generation Wavelets: Performance Evaluation},
volume = {8},
journal = {Electronics},
doi = {10.3390/electronics8010088}
}
@article{ZHANG2019a,
title = {High noise astronomical image denoising via 2G-bandelet denoising compressed sensing},
journal = {Optik},
volume = {184},
pages = {377-388},
year = {2019},
issn = {0030-4026},
doi = {https://doi.org/10.1016/j.ijleo.2019.04.029},
author = {Jie Zhang and Huanlong Zhang and Xiaoping Shi and Shengtao Geng},
keywords = {Cosmic noise, Compressed sensing, Astronomical image denoising, 2G-bandelet, Iterative bandelet thresholding, GSTV-SC method},
abstract = {In deep space exploration, high resolution astronomical image captured is often contaminated by various cosmic noise signals during its shooting and long distance transmission, which has brought inconvenience to astronomical image analysis. The famous compressed sensing (CS) proposed by Candes et al. can successfully solve the problem of high resolution astronomical image compression and low noise reconstruction. In this paper, we further concern how to reconstruct a high quality image from a high resolution and high noise astronomical image. A 2G-bandelet denoising compressed sensing (BDCS) is first proposed based on the advantage of CS in image denoising and the superior ability of 2G-bandelet in sparse representation of astronomical images, then iterative bandelet thresholding (IBT-BTCS) algorithm based on BDCS is proposed for high resolution and high noise astronomical image reconstruction. Firstly, an iterative bandelet thresholding method is designed to obtain optimal approximation of original image; Secondly, to further improve the reconstructed image quality, group sparse total variation with stepsize constraints (GSTV-SC) method is proposed to adjust the reconstructed astronomical image in each iteration. The simulation results show that the proposed algorithm can quickly reconstruct a high quality astronomical image only using a few observations, preserve more astronomical image details and effectively solve high noise astronomical image denoising problem.}
}

@misc{kong2023comparison,
      title={A Comparison of Image Denoising Methods}, 
      author={Zhaoming Kong and Fangxi Deng and Haomin Zhuang and Jun Yu and Lifang He and Xiaowei Yang},
      year={2023},
      eprint={2304.08990},
      archivePrefix={arXiv},
      primaryClass={eess.IV}
}

@article{Vergara2008,
author = {Vergara, Osslan and Ochoa, Humberto and Sànchez, Vianey},
year = {2008},
month = {10},
pages = {207-212},
title = {A Comparison of the Bandelet, Wavelet and Contourlet Transforms for Image Denoising},
volume = {0},
isbn = {978-0-7695-3441-1},
journal = {Mexican International Conference on Artificial Intelligence},
doi = {10.1109/MICAI.2008.63}
}

@article{Dossal2011,
  TITLE = {{Bandlet Image Estimation with Model Selection}},
  AUTHOR = {Dossal, Charles H and Le Pennec, Erwan and Mallat, St{\'e}phane},
  JOURNAL = {{Signal Processing}},
  PUBLISHER = {{Elsevier}},
  VOLUME = {91},
  NUMBER = {12},
  PAGES = {2743-2753},
  YEAR = {2011},
  MONTH = Jan,
  DOI = {10.1016/j.sigpro.2011.01.013},
  PDF = {https://hal.science/hal-00321965v2/file/BandletEstim.pdf},
  HAL_ID = {hal-00321965},
  HAL_VERSION = {v2},
}


@InProceedings{Pennec2007,
  author =	 {Le Pennec, E. and Dossal, Ch. and Peyré, G. and
                  Mallat, S. },
  title =	 {Débruitage géométrique d'image dans des bases
                  orthonormées de bandelettes},
  booktitle =	 {GRETSI 07},
  year =	 2007,
  address =	 {Troyes},
  x-international-audience ={no},
  x-proceedings ={yes},
  x-invited-conference ={no},
  keywords =	 {Actes, Bandlets, ThemeBandlet},
  pubtype =	 {Actes de conférence nationale},
  subject =	 {Bandlets},
  preprint =	 {Bandlets/2007-GRETSI-LPDPM.pdf},
  reprint =	 {Bandlets/2007-GRETSI-LPDPM.pdf},
  url_PDF =
                  {http://lepennec.perso.math.cnrs.fr/Reprint/Bandlets/2007-GRETSI-LPDPM.pdf},
  reprintok =	 1,
  lang =	 {Francais},
  hal =		 {hal-00365965},
}

@inproceedings{Mclaughlin2015,
author = {Mclaughlin, Michael and Grieggs, Samuel and Ezekiel, Soundararajan and Ferris, Michael and Blasch, Erik and Alford, Mark and Cornacchia, Maria and Bubalo, Adnan},
year = {2015},
month = {06},
pages = {},
title = {Bandelet Denoising in Image Processing},
doi = {10.1109/NAECON.2015.7443035}
}

@article{Pennec2005b,
author = {Le Pennec, Erwan and Mallat, Stéphane},
year = {2005},
month = {01},
pages = {},
title = {Bandelet Image Approximation and Compression},
volume = {4},
journal = {Multiscale Modeling \& Simulation},
doi = {10.1137/040619454}
}
@article{Pennec2005a,
author = {Le Pennec, Erwan and Mallat, Stéphane},
year = {2005},
month = {05},
pages = {423-38},
title = {Sparse Geometric Image Representations with Bandelets},
volume = {14},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
doi = {10.1109/TIP.2005.843753}
}

@article{MallatPeyre2007,
author = {Mallat, Stéphane and Peyré, Gabriel},
year = {2007},
month = {07},
pages = {},
title = {A Review of Bandlet Methods for Geometrical Image Representation},
volume = {44},
journal = {Numerical Algorithms},
doi = {10.1007/s11075-007-9092-4}
}


@inproceedings{liu2015faceattributes,
  title = {Deep Learning Face Attributes in the Wild},
  author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
  booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},
  month = {December},
  year = {2015} 
}





@article{Eslahi2016,
author = {Eslahi, Nasser and Aghagolzadeh, Ali},
title = {Compressive Sensing Image Restoration Using Adaptive Curvelet Thresholding and Nonlocal Sparse Regularization},
year = {2016},
issue_date = {July 2016},
publisher = {IEEE Press},
volume = {25},
number = {7},
issn = {1057-7149},
doi = {10.1109/TIP.2016.2562563},
abstract = {Compressive sensing (CS) is a recently emerging technique and an extensively studied problem in signal and image processing, which suggests a new framework for the simultaneous sampling and compression of sparse or compressible signals at a rate significantly below the Nyquist rate. Maybe, designing an effective regularization term reflecting the image sparse prior information plays a critical role in CS image restoration. Recently, both local smoothness and nonlocal self-similarity have led to superior sparsity prior for CS image restoration. In this paper, first, an adaptive curvelet thresholding criterion is developed, trying to adaptively remove the perturbations appeared in recovered images during CS recovery process, imposing sparsity. Furthermore, a new sparsity measure called joint adaptive sparsity regularization (JASR) is established, which enforces both local sparsity and nonlocal 3-D sparsity in transform domain, simultaneously. Then, a novel technique for high-fidelity CS image recovery via JASR is proposed—CS-JASR. To efficiently solve the proposed corresponding optimization problem, we employ the split Bregman iterations. Extensive experimental results are reported to attest the adequacy and effectiveness of the proposed method comparing with the current state-of-the-art methods in CS image restoration.},
journal = {Trans. Img. Proc.},
month = {jul},
pages = {3126–3140},
numpages = {15}
}


@article{Candes2006a,
author = {Candès, Emmanuel and Demanet, Laurent and Donoho, David and Ying, Lexing},
year = {2006},
month = {09},
pages = {},
title = {Fast Discrete Curvelet Transforms},
volume = {5},
journal = {SIAM Journal on Multiscale Modeling and Simulation},
doi = {10.1137/05064182X}
}

@article{Hergt2017,
   title={Searching for cosmic strings in CMB anisotropy maps using wavelets and curvelets},
   volume={2017},
   ISSN={1475-7516},
   DOI={10.1088/1475-7516/2017/06/004},
   number={06},
   journal={Journal of Cosmology and Astroparticle Physics},
   publisher={IOP Publishing},
   author={Hergt, Lukas and Amara, Adam and Brandenberger, Robert and Kacprzak, Tomasz and Réfrégier, Alexandre},
   year={2017},
   month=jun, pages={004–004} 
}

@article{Woiselle2010,
author = {Woiselle, A. and Starck, Jean-Luc and Fadili, Jalal},
year = {2010},
month = {03},
pages = {171-188},
title = {3D Curvelet transforms and Astronomical Data Restoration},
volume = {28},
journal = {Applied and Computational Harmonic Analysis},
doi = {10.1016/j.acha.2009.12.003}
}

@article{Starck2003a,
	author = {{Starck, J. L.} and {Donoho, D. L.} and {Candès, E. J.}},
	title = {Astronomical image representation by the curvelet transform},
	DOI= "10.1051/0004-6361:20021571",
	journal = {\aap},
	year = 2003,
	volume = 398,
	number = 2,
	pages = "785-800"
}

@ARTICLE{Starck2002a,
  author={Jean-Luc Starck and Candes, E.J. and Donoho, D.L.},
  journal={IEEE Transactions on Image Processing}, 
  title={The curvelet transform for image denoising}, 
  year={2002},
  volume={11},
  number={6},
  pages={670-684},
  keywords={Image denoising;Wavelet transforms;Image reconstruction;Interpolation;Wavelet domain;Filter bank;Stability;Computational complexity;Fourier transforms;Sampling methods},
  doi={10.1109/TIP.2002.1014998}
}


@article{Candes2000a,
author = {Emmanuel J. Candes and David L. Donoho},
year = {2000},
month = {11},
pages = {},
title = {Curvelets, Multiresolution Representation, and Scaling Laws},
volume = {4119},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.408568}
}

@article{Donoho2000a,
author = {Donoho, David L.},
title = {Orthonormal Ridgelets and Linear Singularities},
journal = {SIAM Journal on Mathematical Analysis},
volume = {31},
number = {5},
pages = {1062-1099},
year = {2000},
doi = {10.1137/S0036141098344403},
}



@article{Candes2002,
author = {Candès, Emmanuel and Guo, Franck},
year = {2002},
month = {11},
pages = {1519-1543},
title = {New multiscale transforms, minimum total variation synthesis: Applications to edge-preserving image reconstruction},
volume = {82},
journal = {Signal Processing},
doi = {10.1016/S0165-1684(02)00300-6}
}

@article{Boshra2014,
    title   = {{An Analysis and Improvement of the BLS-GSM Denoising Method}},
    author  = {Rajaei, Boshra},
    journal = {{Image Processing On Line}},
    volume  = {4},
    pages   = {44--70},
    year    = {2014},
    note    = {\url{https://doi.org/10.5201/ipol.2014.86}}
}

@inproceedings{Simoncelli1995b,
author = {Simoncelli, E. P. and Freeman, W. T.},
title = {The steerable pyramid: a flexible architecture for multi-scale derivative computation},
year = {1995},
isbn = {0818673109},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {We describe an architecture for efficient and accurate linear decomposition of an image into scale and orientation subbands. The basis functions of this decomposition are directional derivative operators of any desired order. We describe the construction and implementation of the transform.},
booktitle = {Proceedings of the 1995 International Conference on Image Processing (Vol. 3)-Volume 3 - Volume 3},
pages = {3444},
keywords = {transform, steerable pyramid, scale subbands, orientation subbands, multiscale derivative computation, linear image decomposition, image processing, flexible architecture, filters, filtering theory, directional derivative operators, building, basis functions, Fourier transforms, Fourier domain},
series = {ICIP '95}
}

@article{Sze2017EfficientPO,
  title={Efficient Processing of Deep Neural Networks: A Tutorial and Survey},
  author={Vivienne Sze and Yu-hsin Chen and Tien-Ju Yang and Joel S. Emer},
  journal={Proceedings of the IEEE},
  year={2017},
  volume={105},
  pages={2295-2329},
}
@ARTICLE{BrunaMallat2013,
  author={Bruna, Joan and Mallat, Stephane},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Invariant Scattering Convolution Networks}, 
  year={2013},
  volume={35},
  number={8},
  pages={1872-1886},
  keywords={Scattering;Convolution;Fourier transforms;Wavelet coefficients;Computer architecture;Classification;convolution networks;deformations;invariants;wavelets},
  doi={10.1109/TPAMI.2012.230}}

@ARTICLE{2012arXiv1203.1513B,
       author = {{Bruna}, Joan and {Mallat}, St{\'e}phane},
        title = "{Invariant Scattering Convolution Networks}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition},
         year = 2012,
        month = mar,
          eid = {arXiv:1203.1513},
        pages = {arXiv:1203.1513},
          doi = {10.48550/arXiv.1203.1513},
archivePrefix = {arXiv},
       eprint = {1203.1513},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2012arXiv1203.1513B},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{Cheng2020,
   title={A new approach to observational cosmology using the scattering transform},
   volume={499},
   ISSN={1365-2966},
   DOI={10.1093/mnras/staa3165},
   number={4},
   journal={Monthly Notices of the Royal Astronomical Society},
   publisher={Oxford University Press (OUP)},
   author={Cheng, Sihao and Ting, Yuan-Sen and Ménard, Brice and Bruna, Joan},
   year={2020},
   month=oct, pages={5902–5914} }

@inproceedings{Zarka2021,
  TITLE = {{Separation and Concentration in Deep Networks}},
  AUTHOR = {Zarka, John and Guth, Florentin and Mallat, St{\'e}phane},
  BOOKTITLE = {{ICLR 2021 - 9th International Conference on Learning Representations}},
  ADDRESS = {Vienna / Virtual, Austria},
  YEAR = {2021},
  MONTH = May,
  HAL_ID = {hal-03169904},
  HAL_VERSION = {v1},
}

@inproceedings{Zarka2019,
title={Deep Network Classification by Scattering and Homotopy Dictionary Learning},
author={John Zarka and Louis Thiry and Tomas Angles and Stephane Mallat},
booktitle={International Conference on Learning Representations},
year={2020},
}



@ARTICLE{2013arXiv1312.6114K,
       author = {{Kingma}, Diederik P and {Welling}, Max},
        title = "{Auto-Encoding Variational Bayes}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
         year = 2013,
        month = dec,
       eprint = {1312.6114},
 primaryClass = {stat.ML},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



@ARTICLE{2017ITIP...26.3142Z,
       author = {{Zhang}, Kai and {Zuo}, Wangmeng and {Chen}, Yunjin and {Meng}, Deyu and {Zhang}, Lei},
        title = "{Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising}",
      journal = {IEEE Transactions on Image Processing},
     keywords = {Computer Science - Computer Vision and Pattern Recognition},
         year = 2017,
        month = jul,
       volume = {26},
       number = {7},
        pages = {3142-3155},
          doi = {10.1109/TIP.2017.2662206},
 primaryClass = {cs.CV},
}


@inproceedings{Tang2012,
author = {Tang, Yichuan and Salakhutdinov, R. and Hinton, G.},
year = {2012},
month = {06},
pages = {2264-2271},
title = {Robust Boltzmann Machines for recognition and denoising},
isbn = {978-1-4673-1226-4},
journal = {Proceedings / CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition. IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2012.6247936}
}

@ARTICLE{2015arXiv150504597R,
       author = {{Ronneberger}, Olaf and {Fischer}, Philipp and {Brox}, Thomas},
        title = "{U-Net: Convolutional Networks for Biomedical Image Segmentation}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition},
         year = 2015,
        month = may,
          doi = {10.48550/arXiv.1505.04597},
 primaryClass = {cs.CV},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@InProceedings{journals/corr/RonnebergerFB15,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}


@inproceedings{song2021scorebased,
  title={Score-Based Generative Modeling through Stochastic Differential Equations},
  author={Yang Song and Jascha Sohl-Dickstein and Diederik P Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole},
  booktitle={International Conference on Learning Representations},
  year={2021},
}

@article{2018CampagneMallatNotesold,
	author = { Campagne, Jean-Eric},
	title = "Notes et commentaires au sujet des conférences de S. Mallat du Collège de France",
	year = 2018,
	url = {https://github.com/jecampagne/cours_mallat_cdf/blob/main/Notes/Resume-2018.pdf},
}

@unpublished{2018CampagneMallatNotes,
  TITLE = {{Notes et commentaires au sujet des conf{\'e}rences de S. Mallat du Coll{\`e}ge de France (2018)}},
  AUTHOR = {Campagne, Jean-Eric},
  URL = {https://hal.science/hal-04548691},
  TYPE = {Master},
  ADDRESS = {https://www.college-de-france.fr/fr/agenda/cours/apprentissage-face-la-malediction-de-la-grande-dimension, France},
  PAGES = {109},
  INSTITUTION = {{Coll{\`e}ge de France}},
  YEAR = {2018},
  MONTH = Jan,
  KEYWORDS = {Apprentissage automatique Machine Learning ; R{\'e}seau de neurone convolutif ; SVM - Support Vector Machines},
  PDF = {https://hal.science/hal-04548691/file/Resume-2018.pdf},
  HAL_ID = {hal-04548691},
  HAL_VERSION = {v1},
}


@article{2019CampagneMallatNotesold,
	author = { Campagne, Jean-Eric},
	title = "Notes et commentaires au sujet des conférences de S. Mallat du Collège de France",
	year = 2019,
	url = {https://github.com/jecampagne/cours_mallat_cdf/blob/main/Notes/Resume-2019.pdf},
}

@unpublished{2019CampagneMallatNotes,
  TITLE = {{Notes et commentaires au sujet des conf{\'e}rences de S. Mallat du Coll{\`e}ge de France (2019)}},
  AUTHOR = {Campagne, Jean-Eric},
  URL = {https://hal.science/hal-04549194},
  TYPE = {Doctoral},
  ADDRESS = {https://www.college-de-france.fr/fr/agenda/cours/apprentissage-par-reseaux-de-neurones-profonds, France},
  PAGES = {144},
  INSTITUTION = {{Coll{\`e}ge de France}},
  YEAR = {2019},
  MONTH = Jan,
  KEYWORDS = {Apprentissage automatique Machine Learning ; R{\'e}seau de neurone convolutif ; Descente de Gradient ; Mal{\'e}diction de la Dimension},
  PDF = {https://hal.science/hal-04549194/file/Resume-2019.pdf},
  HAL_ID = {hal-04549194},
  HAL_VERSION = {v1},
}

@article{2020CampagneMallatNotesold,
	author = { Campagne, Jean-Eric},
	title = "Notes et commentaires au sujet des conférences de S. Mallat du Collège de France",
	year = 2020,
	url = {https://github.com/jecampagne/cours_mallat_cdf/blob/main/Notes/Resume-2020.pdf},
}

@unpublished{2020CampagneMallatNotes,
  TITLE = {{Notes et commentaires au sujet des conf{\'e}rences de S. Mallat du Coll{\`e}ge de France (2020)}},
  AUTHOR = {Campagne, Jean-Eric},
  URL = {https://hal.science/hal-04549242},
  TYPE = {Master},
  ADDRESS = {https://www.college-de-france.fr/fr/agenda/cours/modeles-multi-echelles-et-reseaux-de-neurones-convolutifs, France},
  PAGES = {146},
  INSTITUTION = {{Coll{\`e}ge de France}},
  YEAR = {2020},
  MONTH = Jan,
  KEYWORDS = {Apprentissage automatique Machine Learning ; R{\'e}seau de neurone convolutif ; Transform{\'e}e de Fourier ; Transform{\'e}e en Ondelettes},
  PDF = {https://hal.science/hal-04549242/file/Resume-2020.pdf},
  HAL_ID = {hal-04549242},
  HAL_VERSION = {v1},
}


@article{2021CampagneMallatNotesold,
	author = { Campagne, Jean-Eric},
	title = "Notes et commentaires au sujet des conférences de S. Mallat du Collège de France",
	year = 2021,
	url = {https://github.com/jecampagne/cours_mallat_cdf/blob/main/Notes/Resume-2021.pdf},
}
@unpublished{2021CampagneMallatNotes,
  TITLE = {{Notes et commentaires au sujet des conf{\'e}rences de S. Mallat du Coll{\`e}ge de France (2021)}},
  AUTHOR = {Campagne, Jean-Eric},
  URL = {https://hal.science/hal-04549376},
  TYPE = {Master},
  ADDRESS = {France},
  PAGES = {139},
  INSTITUTION = {{Coll{\`e}ge de France}},
  YEAR = {2021},
  MONTH = Jan,
  KEYWORDS = {Apprentissage automatique Machine Learning ; R{\'e}seau de neurone convolutif ; Transform{\'e}e de Fourier ; Transform{\'e}e en Ondelettes ; JPEG ; JPEG2000},
  PDF = {https://hal.science/hal-04549376/file/Resume-2021.pdf},
  HAL_ID = {hal-04549376},
  HAL_VERSION = {v1},
}

@article{2022CampagneMallatNotesold,
	author = { Campagne, Jean-Eric},
	title = "Notes et commentaires au sujet des conférences de S. Mallat du Collège de France",
	year = 2022,
	url = {https://github.com/jecampagne/cours_mallat_cdf/blob/main/Notes/Resume-2022.pdf},
}

@unpublished{2022CampagneMallatNotes,
  TITLE = {{Notes et commentaires au sujet des conf{\'e}rences de S. Mallat du Coll{\`e}ge de France (2022)}},
  AUTHOR = {Campagne, Jean-Eric},
  URL = {https://hal.science/hal-04549438},
  TYPE = {Master},
  ADDRESS = {https://www.college-de-france.fr/fr/agenda/cours/information-et-complexite, France},
  PAGES = {134},
  INSTITUTION = {{Coll{\`e}ge de France}},
  YEAR = {2022},
  MONTH = Jan,
  KEYWORDS = {Apprentissage automatique Machine Learning ; R{\'e}seau de neurone convolutif ; Information de Fisher ; Entropie de Shannon ; JPEG ; JPEG2000 ; MPEG ; Codage entropique ; Inf{\'e}rence},
  PDF = {https://hal.science/hal-04549438/file/Resume-2022.pdf},
  HAL_ID = {hal-04549438},
  HAL_VERSION = {v1},
}


@article{2023CampagneMallatNotesold,
	author = { Campagne, Jean-Eric},
	title = "Notes et commentaires au sujet des conférences de S. Mallat du Collège de France",
	year = 2023,
	url = {https://github.com/jecampagne/cours_mallat_cdf/blob/main/Notes/Resume-2023.pdf},
}

@unpublished{2023CampagneMallatNotes,
  TITLE = {{Notes et commentaires au sujet des conf{\'e}rences de S. Mallat du Coll{\`e}ge de France (2023)}},
  AUTHOR = {Campagne, Jean-Eric},
  URL = {https://hal.science/hal-04549532},
  TYPE = {Master},
  ADDRESS = {https://www.college-de-france.fr/fr/agenda/cours/modeles-information-et-physique-statistique, France},
  PAGES = {157},
  INSTITUTION = {{Coll{\`e}ge de France}},
  YEAR = {2023},
  MONTH = Jan,
  KEYWORDS = {Apprentissage automatique Machine Learning ; R{\'e}seau de neurone convolutif ; Entropie de Shannon ; Entropie Maximale ; Chaine de Markov ; Processus ergodique ; Physique Statistique},
  PDF = {https://hal.science/hal-04549532/file/Resume-2023%20%281%29.pdf},
  HAL_ID = {hal-04549532},
  HAL_VERSION = {v1},
}

@article{2024CampagneMallatNotesold,
	author = { Campagne, Jean-Eric},
	title = "Notes et commentaires au sujet des conférences de S. Mallat du Collège de France",
	year = 2024,
	url = {https://github.com/jecampagne/cours_mallat_cdf/blob/main/Notes/Resume-2024.pdf},
}

@unpublished{2024CampagneMallatNotes,
  TITLE = {{Notes et commentaires au sujet des conf{\'e}rences de S. Mallat du Coll{\`e}ge de France (2024)}},
  AUTHOR = {Campagne, Jean-Eric},
  URL = {https://hal.science/hal-04549633},
  TYPE = {Doctoral},
  ADDRESS = {https://www.college-de-france.fr/fr/agenda/cours/apprentissage-et-generation-par-echantillonnage-aleatoire, France},
  PAGES = {169},
  INSTITUTION = {{Coll{\`e}ge de France}},
  YEAR = {2024},
  MONTH = Jan,
  KEYWORDS = {Apprentissage automatique Machine Learning ; R{\'e}seau de neurone convolutif ; Chaine de markov ; Algorithmes MCMC ; Mod{\`e}le g{\'e}n{\'e}ratif ; Information de Fisher ; Entropie de Shannon ; Equation d'Ornstein-Uhlenbeck},
  PDF = {https://hal.science/hal-04549633/file/Resume-2024.pdf},
  HAL_ID = {hal-04549633},
  HAL_VERSION = {v1},
}


@book{MallatWavelet2008,
author = {Mallat, Stéphane},
title = {A Wavelet Tour of Signal Processing, Third Edition: The Sparse Way},
year = {2008},
isbn = {0123743702},
publisher = {Academic Press, Inc.},
address = {USA},
edition = {3rd},
abstract = {Mallat's book is the undisputed reference in this field - it is the only one that covers the essential material in such breadth and depth. - Laurent Demanet, Stanford UniversityThe new edition of this classic book gives all the major concepts, techniques and applications of sparse representation, reflecting the key role the subject plays in today's signal processing. The book clearly presents the standard representations with Fourier, wavelet and time-frequency transforms, and the construction of orthogonal bases with fast algorithms. The central concept of sparsity is explained and applied to signal compression, noise reduction, and inverse problems, while coverage is given to sparse representations in redundant dictionaries, super-resolution and compressive sensing applications.Features:* Balances presentation of the mathematics with applications to signal processing* Algorithms and numerical examples are implemented in WaveLab, a MATLAB toolbox* Companion website for instructors and selected solutions and code available for studentsNew in this edition* Sparse signal representations in dictionaries* Compressive sensing, super-resolution and source separation* Geometric image processing with curvelets and bandlets* Wavelets for computer graphics with lifting on surfaces* Time-frequency audio processing and denoising* Image compression with JPEG-2000* New and updated exercisesA Wavelet Tour of Signal Processing: The Sparse Way, third edition, is an invaluable resource for researchers and R\&D engineers wishing to apply the theory in fields such as image processing, video processing and compression, bio-sensing, medical imaging, machine vision and communications engineering.Stephane Mallat is Professor in Applied Mathematics at cole Polytechnique, Paris, France. From 1986 to 1996 he was a Professor at the Courant Institute of Mathematical Sciences at New York University, and between 2001 and 2007, he co-founded and became CEO of an image processing semiconductor company.Companion website: A Numerical Tour of Signal Processing Includes all the latest developments since the book was published in 1999, including itsapplication to JPEG 2000 and MPEG-4Algorithms and numerical examples are implemented in Wavelab, a MATLAB toolboxBalances presentation of the mathematics with applications to signal processing}
}
}
