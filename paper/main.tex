\documentclass[11pt]{amsart}
\usepackage{amsaddr}
\usepackage{mathtools}
\usepackage{aas_macros} % macro pour Bibtex
\usepackage{hyperref}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsthm}
\usepackage{amsmath}
% \usepackage{makecell}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{color}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{pifont}
\usepackage{natbib,fancyhdr} %new

%\usepackage{mathtools} % psmallmatrix

\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

\setlength{\heavyrulewidth}{3\lightrulewidth}
\setlength{\abovetopsep}{1ex}

\usepackage[top=3cm, bottom=2cm, left=3cm, right=2cm]{geometry} %margins

% \usepackage{geometry}
%  \geometry{
%  a4paper,
%  left=25mm,
%  }

\newcommand{\jessa}[1]{{\color{red} #1}}
\newcommand{\field}[1]{\mathbf{#1}}
\newcommand{\nn}{\nonumber}


% My definitions:
\def\U{\mathcal U}
\def\LL{\mathcal L}
\def\P{\mathcal P}
\def\D{\mathcal D}

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

% My packages:
\usepackage{algorithmic}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\usepackage{xcolor}
\usepackage{multicol} 
\usepackage{enumitem}
\newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{blue}{#1}}
\SetCommentSty{mycommfont}
\newcommand{\bl}[1]{{\color{blue} #1}}
\newcommand{\rd}[1]{{\color{red} #1}}


% Alternative Assumption!

\newtheorem{theorem}{Theorem}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{definition}{Definition}

% New environment
\newenvironment{assumptionp}[1]{
  \renewcommand\theassumptionalt{#1}
  \assumptionalt
}{\endassumptionalt}

\graphicspath{{./figures}}
\usepackage[margin=1cm]{caption}



\title{Galaxy image statistical generator: how to be confident?}
\author{Jean-Eric Campagne}
\address{Université Paris-Saclay, CNRS/IN2P3, IJCLab, 91405 Orsay, France
}
\email{jean-eric.campagne@ijclab.in2p3.fr}
\date{\today}

\begin{document}
\maketitle
%\renewcommand{\baselinestretch}{0.75}\normalsize
%\tableofcontents
%\renewcommand{\baselinestretch}{1.0}\normalsize
%
\begin{abstract}
blabla
\\
\smallskip
\noindent \textbf{Keywords.} diffusion models, U-Net
\end{abstract}

\section{Introduction}
\label{sec:Intro}
Image generation in Machine Learning is a challenging task that has made a dramatic rise in quality recently thanks to the large scale statistical model architectures as for instance \texttt{DALL-E 2} \citep{ramesh2022}, \texttt{Midjourney} \citep{Oppenlaender2022} and \texttt{StableDiffusion} \citep{Rombach2022} which use \textit{stochastic diffusion processes}. Such models have replaced the previous generation based on \textit{variational auto encoder} (aka VAE) \citep{Kingma2014} and  \textit{adversarial networks} (aka GAN) \citep{goodfellow2014generative} as in \citep{KarrasALL18}, or \textit{normalizing flows} (hereafter nicknamed NF) such as in \texttt{Glow} \citep{Kingma2018}. 


The ability of generative models have been rapidly adopted in many domains. For instance, in High Energy Physics the reader may be interested by the review \cite{PhysRevD.107.076017}. Concerning Astrophysics and Cosmology the generative models are used in different tasks (eg. deblending \citep{Hemmati_2022,Arcelin2020} {\color{red} à compléter}) and especially to create synthetic galaxy images of complex morphologies going beyond parametrized analytic light profile simulations (eg. \texttt{GalSim} by \cite{ROWE2015121}). Along this line \citep{ravanbakhsh2016,Fussell2019} use GAN models, \cite{Lanusse2021} propose an hybrid VAE-Normalizing Flow architecture and \cite{smith2021} use a denoising stochastic diffusion model (hereafter nicknamed DSDM). 

Despite the impressive image quality of these generative models that are nowadays well diffused in the general public, many questions arise from mathematical and usage point of views. Notably, one may ask for what is really learned by the generative models and what are the statistical properties of the generated samples. In a general manner \cite{Hataya2023} ask if the image generated can corrupt the future datasets. However, the study is devoted  to the large scale statistical models mentioned above that are trained usually with billion-scale data extracted from the Internet, and so in turn can be contaminated by the images shared by many users. Concerning galaxy image generation the datasets are much more modest for the time being (i.e $O(10^5)$) collected from optical surveys (eg. COSMOS HST Advanced Camera for Surveys, \cite{mandelbaum_2019_3242143},  Sloan Digital Sky Survey \citep[SDSS;][]{sdss} Data Release 7 \citep{sdssdr7}) and used by a rather small community compared to social network followers which certainly  limits the datasets corruption. So, besides image corruption, \cite{HACKSTEIN2023100685,janulewicz2024assessing} have investigated different metrics to address the question of fidelity of the generated galaxy images and morphological properties compared to the original dataset.

\cite{kadkhodaie2024generalization} address more mathematically oriented questions and demonstrate the passage between memorization to generalization of  diffusion generative models when the dataset size increases and propose interpretation of what is learned by the network as a sort of \textit{geometry-adaptive harmonic basis} going beyond the commonly used \textit{steerable wavelet basis} first introduced and studied in \cite{Simoncelli1995b,Unser2013} and developped for instance in the \texttt{Kyamato} library \citep{JMLR:v21:19-047}. The authors uses \textit{denoiser} architectures as \texttt{UNet} \citep{2015arXiv150504597R} and \texttt{BF-CNN} networks \citep{Mohan2020Robust} trained on \texttt{CelebA} \citep{Liu2015} and \texttt{LSUN} bedroom  \citep{Yu2015} reduced datasets of $O(10^5)$ images resized to $80\times 80$ pixels (grayscale). The method and image dataset characteristics are the starting point to investigate how the \texttt{Glow} normalizing flow based model compare to denoiser based diffusion model concerning the generation of galaxy images both trained with the same dataset issued from SDSS suvey.


In the following sections, first we briefly describe the different kind of generative models and we show the outcome of the conducted numerical experiment before drawing some guide lines. Appendix gives more details on the dataset used.


%\begin{figure}
%\centering
%\includegraphics[width=0.4\columnwidth]{filtreDb4.png}
%\caption{Coverage of the Fourier domain without gap by a low-pass filter and a collection of band-pass filters.}
%\label{fig-Daubechies-db4}
%\end{figure}


\section{Summary}


\section*{Acknowledgements}

\section*{Codes}


%%%%%%%%%%
\addcontentsline{toc}{section}{References}
% Put your bibiliography file here
%\section{Bibliography}
\bibliographystyle{elsarticle-harv}%{aa}
\bibliography{refs.bib}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
